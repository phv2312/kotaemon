import asyncio
from copy import deepcopy
from typing import Optional

import gradio as gr
from ktem.app import BasePage
from ktem.components import reasonings
from ktem.db.models import Conversation, engine
from sqlmodel import Session, select

from .chat_panel import ChatPanel
from .common import STATE
from .control import ConversationControl
from .report import ReportIssue


class ChatPage(BasePage):
    def __init__(self, app):
        self._app = app
        self._indices_input = []
        self.on_building_ui()

    def on_building_ui(self):
        with gr.Row():
            self.chat_state = gr.State(STATE)
            with gr.Column(scale=1):
                self.chat_control = ConversationControl(self._app)

                for index in self._app.index_manager.indices:
                    index.selector = -1
                    index_ui = index.get_selector_component_ui()
                    if not index_ui:
                        continue

                    index_ui.unrender()
                    with gr.Accordion(label=f"{index.name} Index", open=False):
                        index_ui.render()
                        gr_index = index_ui.as_gradio_component()
                        if gr_index:
                            index.selector = len(self._indices_input)
                            self._indices_input.append(gr_index)
                        setattr(self, f"_index_{index.id}", index_ui)

                self.report_issue = ReportIssue(self._app)
            with gr.Column(scale=6):
                self.chat_panel = ChatPanel(self._app)
            with gr.Column(scale=3):
                with gr.Accordion(label="Information panel", open=True):
                    self.info_panel = gr.HTML(elem_id="chat-info-panel")

    def on_register_events(self):
        gr.on(
            triggers=[
                self.chat_panel.text_input.submit,
                self.chat_panel.submit_btn.click,
            ],
            fn=self.chat_panel.submit_msg,
            inputs=[self.chat_panel.text_input, self.chat_panel.chatbot],
            outputs=[self.chat_panel.text_input, self.chat_panel.chatbot],
            show_progress="hidden",
        ).then(
            fn=self.chat_fn,
            inputs=[
                self.chat_control.conversation_id,
                self.chat_panel.chatbot,
                self._app.settings_state,
                self.chat_state,
            ]
            + self._indices_input,
            outputs=[
                self.chat_panel.chatbot,
                self.info_panel,
                self.chat_state,
            ],
            show_progress="minimal",
        ).then(
            fn=self.update_data_source,
            inputs=[
                self.chat_control.conversation_id,
                self.chat_panel.chatbot,
                self.chat_state,
            ]
            + self._indices_input,
            outputs=None,
        )

        self.chat_panel.regen_btn.click(
            fn=self.regen_fn,
            inputs=[
                self.chat_control.conversation_id,
                self.chat_panel.chatbot,
                self._app.settings_state,
                self.chat_state,
            ]
            + self._indices_input,
            outputs=[
                self.chat_panel.chatbot,
                self.info_panel,
                self.chat_state,
            ],
            show_progress="minimal",
        ).then(
            fn=self.update_data_source,
            inputs=[
                self.chat_control.conversation_id,
                self.chat_panel.chatbot,
                self.chat_state,
            ]
            + self._indices_input,
            outputs=None,
        )

        self.chat_panel.chatbot.like(
            fn=self.is_liked,
            inputs=[self.chat_control.conversation_id],
            outputs=None,
        )

        self.chat_control.conversation.change(
            self.chat_control.select_conv,
            inputs=[self.chat_control.conversation],
            outputs=[
                self.chat_control.conversation_id,
                self.chat_control.conversation,
                self.chat_control.conversation_rn,
                self.chat_panel.chatbot,
                self.chat_state,
            ]
            + self._indices_input,
            show_progress="hidden",
        )

        self.report_issue.report_btn.click(
            self.report_issue.report,
            inputs=[
                self.report_issue.correctness,
                self.report_issue.issues,
                self.report_issue.more_detail,
                self.chat_control.conversation_id,
                self.chat_panel.chatbot,
                self._app.settings_state,
                self._app.user_id,
                self.chat_state,
            ]
            + self._indices_input,
            outputs=None,
        )

    def update_data_source(self, convo_id, messages, state, *selecteds):
        """Update the data source"""
        if not convo_id:
            gr.Warning("No conversation selected")
            return

        selecteds_ = {}
        for index in self._app.index_manager.indices:
            if index.selector != -1:
                selecteds_[str(index.id)] = selecteds[index.selector]

        with Session(engine) as session:
            statement = select(Conversation).where(Conversation.id == convo_id)
            result = session.exec(statement).one()

            data_source = result.data_source
            result.data_source = {
                "selected": selecteds_,
                "messages": messages,
                "state": state,
                "likes": deepcopy(data_source.get("likes", [])),
            }
            session.add(result)
            session.commit()

    def is_liked(self, convo_id, liked: gr.LikeData):
        with Session(engine) as session:
            statement = select(Conversation).where(Conversation.id == convo_id)
            result = session.exec(statement).one()

            data_source = deepcopy(result.data_source)
            likes = data_source.get("likes", [])
            likes.append([liked.index, liked.value, liked.liked])
            data_source["likes"] = likes

            result.data_source = data_source
            session.add(result)
            session.commit()

    def create_pipeline(self, settings: dict, state: dict, *selecteds):
        """Create the pipeline from settings

        Args:
            settings: the settings of the app
            is_regen: whether the regen button is clicked
            selected: the list of file ids that will be served as context. If None, then
                consider using all files

        Returns:
            - the pipeline objects
        """
        reasoning_mode = settings["reasoning.use"]
        reasoning_cls = reasonings[reasoning_mode]
        reasoning_id = reasoning_cls.get_info()["id"]

        # get retrievers
        retrievers = []
        for index in self._app.index_manager.indices:
            index_selected = []
            if index.selector != -1:
                index_selected = selecteds[index.selector]
            iretrievers = index.get_retriever_pipelines(settings, index_selected)
            retrievers += iretrievers

        # prepare states
        reasoning_state = {
            "app": deepcopy(state["app"]),
            "pipeline": deepcopy(state.get(reasoning_id, {})),
        }

        pipeline = reasoning_cls.get_pipeline(settings, reasoning_state, retrievers)

        return pipeline, reasoning_state

    async def chat_fn(self, conversation_id, chat_history, settings, state, *selecteds):
        """Chat function"""
        chat_input = chat_history[-1][0]
        chat_history = chat_history[:-1]

        queue: asyncio.Queue[Optional[dict]] = asyncio.Queue()

        # construct the pipeline
        pipeline, reasoning_state = self.create_pipeline(settings, state, *selecteds)
        pipeline.set_output_queue(queue)

        asyncio.create_task(pipeline(chat_input, conversation_id, chat_history))
        text, refs = "", ""

        len_ref = -1  # for logging purpose

        while True:
            try:
                response = queue.get_nowait()
            except Exception:
                state[pipeline.get_info()["id"]] = reasoning_state["pipeline"]
                yield chat_history + [(chat_input, text or "Thinking ...")], refs, state
                continue

            if response is None:
                queue.task_done()
                print("Chat completed")
                break

            if "output" in response:
                text += response["output"]

            if "evidence" in response:
                if response["evidence"] is None:
                    refs = ""
                else:
                    refs += response["evidence"]

            if len(refs) > len_ref:
                print(f"Len refs: {len(refs)}")
                len_ref = len(refs)

        state[pipeline.get_info()["id"]] = reasoning_state["pipeline"]
        yield chat_history + [(chat_input, text)], refs, state

    async def regen_fn(
        self, conversation_id, chat_history, settings, state, *selecteds
    ):
        """Regen function"""
        if not chat_history:
            gr.Warning("Empty chat")
            yield chat_history, "", state
            return

        state["app"]["regen"] = True
        async for chat, refs, state in self.chat_fn(
            conversation_id, chat_history, settings, state, *selecteds
        ):
            new_state = deepcopy(state)
            new_state["app"]["regen"] = False
            yield chat, refs, new_state
        else:
            state["app"]["regen"] = False
            yield chat_history, "", state
